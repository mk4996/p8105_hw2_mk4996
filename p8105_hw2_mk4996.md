p8105_hw2_mk4996
================
Miho Kawanami
2025-09-27

# Problem 1

## First: Cleaning the data in pols-month.csv.

``` r
pols_df = read_csv(file = "./pols-month.csv", 
                          na = c(".", "NA", ""), 
                          show_col_types = FALSE) |>
  clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  mutate(
    month = factor(month.name[month], levels = month.name, ordered = TRUE),
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem",
      TRUE ~ NA_character_
    )) |>
  select(-day, -prez_dem, -prez_gop)
```

## Second: Cleaning the data in snp.csv.

``` r
snp_df = read_csv(file = "./snp.csv",
                         na = c(".", "NA", ""),
                         show_col_types = FALSE) |>
  clean_names() |>
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) |>
  mutate(
  year = ifelse(year < 20, year + 2000, year + 1900),  
  month = factor(month.name[month], levels = month.name, ordered = TRUE)) |>
  select(year, month, close) |>
  arrange(year, month)
```

## Third: Tidying the unemployment data

``` r
unemp_df = read_csv(file = "./unemployment.csv",
                         na = c(".", "NA", ""),
                         show_col_types = FALSE) |>
  clean_names() |>
  pivot_longer(-year, names_to = "month", values_to = "unemployment") |>
  mutate(
    month = match(tolower(month), tolower(month.abb)),
    month = factor(month.name[month], levels = month.name, ordered = TRUE)
  ) |>
  arrange(year, month)
```

## Join the datasets

``` r
pols_snp  = left_join(pols_df, snp_df,  by = c("year","month"))
final_df  = left_join(pols_snp, unemp_df, by = c("year","month")) |>
  arrange(year, month)
```

## Write a short paragraph about these datasets

The `pols-month` dataset contained the number of national politicians
who are democratic or republican at any given time. The `snp` dataset
contained Standard & Poor’s stock market index (S&P), often used as a
representative measure of stock market as a whole. The `unemployment`
dataset reports monthly unemployment percentages.

After merging, the resulting dataset has 822 rows and 11 columns,
ranging years 1947 to 2015.  
Key variables include `year`, `month`, `president`, `close` (the closing
values of the S&P stock index), and `unemployment`.

# Problem2

## Cleaning the data in Mr. Trash Wheel

``` r
library(readxl)
mr_trash = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N655") |> 
  clean_names() |> 
  drop_na(dumpster) |> 
  mutate(year = parse_integer(as.character(year)),
        (sports_balls = as.integer(round(sports_balls))),
        (trash_wheel = "Mr. Trash Wheel")) 
```

## Cleaning the data in Professor Trash Wheel

``` r
prof_trash = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M123") |> 
  clean_names() |> 
  drop_na(dumpster) |> 
  mutate(trash_wheel = "Professor Trash Wheel")
```

## Cleaning the data in Gwynnda Trash Wheel

``` r
gwynnda = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L266") |> 
  clean_names() |> 
  drop_na(dumpster) |> 
  mutate(trash_wheel = "Gwynnda Trash Wheel")
```

## Combine the datasets

``` r
trash_data = bind_rows(mr_trash, prof_trash, gwynnda)
```

## Write a short paragraph about these datasets

Mr. Trash Wheel is a water-wheel vessel that intercepts litter and
debris in Baltimore’s Inner Harbor; the public spreadsheet records
dumpster-level collections, including dates, weights/volumes, and counts
of common items. Using those sheets, I combined the Mr., Professor, and
Gwynnda data into a single tidy dataset with 1033 observations across 3
devices. Each row corresponds to one dumpster and includes fields such
as `dumpster`, `date`, `year`, `month`, `weight_tons`,
`volume_cubic_yards`, and item counts (e.g., `plastic_bottles`,
`polystyrene`, `cigarette_butts`, `glass_bottles`, `plastic_bags`,
`wrappers`; `sports_balls` is recorded only on some sheets). For the
available data, **Professor Trash Wheel** collected a total of 246.7
tons of trash, and **Gwynnda** collected 18120 cigarette butts in June
2022.

# Problem 3

## Cleaning the data in Zip Codes

``` r
library(janitor)
zip_codes = read_csv("./Zip Codes.csv", na = c(".", "NA",
""), show_col_types = FALSE) |>
  clean_names() |>
  mutate(
    zip = as.character(zip_code),  
    borough = recode(
      county,
      "New York" = "Manhattan",
      "Kings"    = "Brooklyn",
      "Queens"   = "Queens",
      "Bronx"    = "Bronx",
      "Richmond" = "Staten Island"
  )) |>
select(zip, neighborhood, borough) |>
  group_by(zip) |>
  summarise(
    borough      = stringr::str_c(sort(unique(na.omit(borough))), collapse = " / "),
    neighborhood = stringr::str_c(sort(unique(na.omit(neighborhood))), collapse = ", "),
    .groups = "drop"
  )
```

## Cleaning the data in Zip zori

``` r
zori_wide = read_csv("./Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", show_col_types = FALSE) |>
  clean_names() |>
  rename(zip = region_name) |>
  mutate(zip = sprintf("%05s", gsub("\\D", "", as.character(zip))))

date_cols = names(zori_wide)[grepl("^x\\d{4}_\\d{2}_\\d{2}$", names(zori_wide))]

zori_long = zori_wide |>
  pivot_longer(
    cols = all_of(date_cols),
    names_to = "date",
    values_to = "zori"
  ) |>
  mutate(date = as.Date(gsub("^x", "", gsub("_", "-", date)), format = "%Y-%m-%d")) |>
  arrange(zip, date)
```

## Join the data in Zip Codes and in Zip zori

``` r
full = zori_long |>
  left_join(zip_codes, by = "zip", relationship = "many-to-one")
```
